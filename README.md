# Rethinking Popularity Bias in Collaborative Filtering via Analytical Vector Decomposition

This repository contains the official source code and experimental data for the paper "Rethinking Popularity Bias in Collaborative Filtering via Analytical Vector Decomposition".

Our work proposes **DDC (Directional Decomposition and Correction)**, a novel finetuning framework to mitigate popularity bias.

## Framework Overview

![Framework](assets/framework.png)

## Repository Structure

Here is a breakdown of the key files and directories in this project:

```
ddc/
├── assets/
│   └── framework.pdf               # Main framework illustration from the paper.
├── e_pop_saved/                    # This directory will store the generated e_pop vectors.
├── original_result_in_paper/
│   ├── MF/                         # Original training logs for the baseline BPR model.
│   └── MFDDC/                      # Original training logs for our MFDDC model.
├── get_e_pop.ipynb                 # Jupyter notebook to extract the e_pop vector.
├── mf.py                           # Script to train the baseline BPR model.
└── mfddc.py                        # Script to finetune the model with our MFDDC method.
```

- **`assets/`**: Contains visual assets used in the paper.
- **`e_pop_saved/`**: This directory is initially empty. It will store the popularity direction vectors (`e_pop`) generated by `get_e_pop.ipynb`.
- **`original_result_in_paper/`**: Contains the raw training logs for both the baseline and our proposed MFDDC model across all three datasets, serving as proof of our reported results.
- **`get_e_pop.ipynb`**: A notebook to compute and extract the `e_pop` vector from a trained model's item embeddings.
- **`mf.py`**: The script for training the baseline BPR model.
- **`mfddc.py`**: The main script for finetuning a pre-trained model with our proposed DDC method.

## Installation

You can set up the required environment using Conda.

1. **Create and activate a new Conda environment:**

    ```bash
    conda create --name ddc python==3.9
    conda activate ddc
    ```

2. **Install the necessary packages:**

    ```bash
    pip install recbole==1.2.1
    pip install torch==2.1.0
    pip install numpy==1.26.0
    pip install pandas==2.2.2
    ```

## How to Reproduce Results

To reproduce the results from our paper, you must perform the following three steps in sequential order. We use the **Tmall** dataset as the primary example.

### Step 1: Train the Base Model

First, train the base BPR model. This script will generate the necessary pre-trained model checkpoint (`.pth` file). The `--dataset_id` argument selects the dataset (0: Amazon, 1: Yelp, 2: Tmall).

```bash
# Example for Tmall dataset
python mf.py -g 0 -d 2
```

This will train the model and save a checkpoint file inside the `./saved/` directory. **Make a note of the full path to this new `.pth` file**, as it is required for the next step.

#### Step 2: Extract the Popularity Direction (`e_pop`)

Next, extract the popularity direction from the item embeddings of the model you just trained.

1. Open the Jupyter Notebook `get_e_pop.ipynb`.
2. Locate the cell containing the `MODEL_FILE` variable:

    ```python
    # ddc/get_e_pop.ipynb

    MODEL_FILE = './saved/BPR-Aug-02-2025_19-28-56.pth' 
    ```

3. **Update this path** to match the exact checkpoint file generated in Step 1.
4. Run the entire notebook. A new `.json` file containing the `e_pop` vector will be saved in the corresponding dataset folder inside `./e_pop_saved/` (e.g., `./e_pop_saved/tmall/`). **Make a note of the path to this new `.json` file.**

### Step 3: Finetune with MFDDC

Finally, run the MFDDC finetuning script using the artifacts generated in the previous steps.

1. Open the script `mfddc.py`.
2. Locate and **update the `DEFAULT_MODEL_FILE` and `DEFAULT_REP_DIRECTION_FILE` lists** with the full paths to the `.pth` and `.json` files you generated.

    ```python
    # ddc/mfddc.py

    # Example for Tmall (index 2)
    DEFAULT_MODEL_FILE = [
        './saved/path_to_your_amazon_model.pth',   # amazon
        './saved/path_to_your_yelp_model.pth',     # yelp
        './saved/path_from_step_1.pth',            # tmall (UPDATE THIS)
    ]
    DEFAULT_REP_DIRECTION_FILE = [
        './e_pop_saved/amazon/your_amazon_direction.json', # amazon
        './e_pop_saved/yelp/your_yelp_direction.json',     # yelp
        './e_pop_saved/tmall/path_from_step_2.json',       # tmall (UPDATE THIS)
    ]
    ```

3. Run the script with the desired hyperparameters.

    ```bash
    # Example for Tmall dataset
    python mfddc.py --gpu_id 0 --use_epre --epre_sort_mode 'y_uio' --epre_select_mode 'top' --epre_agg_mode 'mean' --epre_topk 0.3 --loss_combination 'b_a' --dataset_index 2
    ```

    This will start the finetuning process and reproduce the results reported in our paper.

## Reproducibility Statement

Our work places a strong emphasis on reproducibility. The random seeds for all components (numpy, torch, and data splitting) have been fixed. By following the steps outlined above, you will be able to obtain results that are **identical** to those reported in our paper. The original training logs are also provided in the `original_result_in_paper/` directory for verification.
